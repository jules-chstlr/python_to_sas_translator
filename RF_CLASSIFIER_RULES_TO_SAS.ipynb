{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import export_text\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rules(tree, tree_id: int , features: list, sas_table: str, max_depth=100, spacing=2):\n",
    "    \"\"\" \n",
    "    Extract the rules of a decision tree and translate them to SAS code.\n",
    "    Create a SAS dataset representing those rules.\n",
    "    \n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    tree: sklearn DecisionTreeClassifier\n",
    "        the tree whose decision rules we want to extract\n",
    "    tree_id: int\n",
    "        tree identifier (0 to numbers of trees -1)\n",
    "    features: list\n",
    "        list of model features\n",
    "    sas_table: str\n",
    "        name of the SAS dataset containing the decision tree features\n",
    "    max_depth: int\n",
    "        number of levels of the tree considered (default is 100 - must be greater than 1)\n",
    "        more information : https://scikit-learn.org/stable/modules/generated/sklearn.tree.export_text.html\n",
    "    spacing: int\n",
    "        number of spaces between edges (default is 2)\n",
    "        more information : https://scikit-learn.org/stable/modules/generated/sklearn.tree.export_text.html      \n",
    "    \"\"\"\n",
    "    if spacing < 2:\n",
    "        raise ValueError('spacing must be > 1')\n",
    "    # export decision tree to text, using sklearn.tree function\n",
    "    rules = export_text(tree, feature_names=features, \n",
    "                        max_depth=max_depth,\n",
    "                        decimals=6,\n",
    "                        spacing=spacing-1)\n",
    "    # translate text to SAS code\n",
    "    rules_in_sas = translate_text_to_sas(tree, tree_id, sas_table, features, rules, spacing)\n",
    "    return rules_in_sas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_text_to_sas(tree, tree_id: int, sas_table: str, features: list, text: str, spacing=2):\n",
    "    \"\"\" \n",
    "    Translate tree rules to SAS code, into a dataset.\n",
    "    \n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    tree: sklearn DecisionTreeClassifier\n",
    "        the tree whose decision rules we want to extract\n",
    "    tree_id: int\n",
    "        tree identifier (0 to numbers of trees -1)\n",
    "    features: list\n",
    "        list of model features\n",
    "    sas_table: str\n",
    "        name of the SAS dataset containing the decision tree features\n",
    "        a column \"PREDICTED_VALUE_i\" will be added to this dataset (i matches tree identifier)\n",
    "    text: str\n",
    "        rules obtained with export_text function\n",
    "    spacing: int\n",
    "        number of spaces between edges (default is 2)\n",
    "        more information : https://scikit-learn.org/stable/modules/generated/sklearn.tree.export_text.html      \n",
    "    \"\"\"\n",
    "    skip, dash = ' '*spacing, '-'*(spacing-1) # handling spacing\n",
    "    sas_rules = 'DATA DECISION_TREE_' + str(tree_id + 1) + ';\\n'\n",
    "    sas_rules += 'SET {};\\n'.format(sas_table)\n",
    "    splitted_rules = text.split('\\n') # Make a list of rules\n",
    "    dict_space_count = {} # keys: number of eft spaces, values: number of rows with this number\n",
    "    current_elseif_count = [] # for handling \"END;\" ASSOCIATED WITH \"ELSE IF\" conditions. Add as many \"END;\" as nested \"ELSE IFs\"\n",
    "    #add_end = 0\n",
    "    # Iterate through rules\n",
    "    for i, line in enumerate(splitted_rules):\n",
    "        line = line.rstrip().replace('|',' ').replace('-', ' ')\n",
    "        n_spaces = len(line) - len(line.lstrip(' ')) # get spaces from left\n",
    "        # Update dictionary for handling whether IF or ELSE IF\n",
    "        if str(n_spaces) not in dict_space_count.keys():\n",
    "            dict_space_count[str(n_spaces)] = 1\n",
    "        else: \n",
    "            dict_space_count[str(n_spaces)] += 1\n",
    "        # Pair --> ELSE\n",
    "        if 'class' in line:\n",
    "            dict_space_count[str(n_spaces)] -= 1 # do not count rows where predicted value is computed\n",
    "        front_add = get_front_add(dict_space_count[str(n_spaces)], n_spaces)\n",
    "        add_end_front = ''\n",
    "        if len(current_elseif_count):\n",
    "            if n_spaces < current_elseif_count[-1]:\n",
    "                add_end_front = ''\n",
    "                while(n_spaces < current_elseif_count[-1]):\n",
    "                    add_end_front += 'END;\\n'\n",
    "                    current_elseif_count.pop() # last element corresponds to current front spaces in line\n",
    "                    if not len(current_elseif_count):\n",
    "                        break\n",
    "        if 'ELSE' in front_add and 'class' not in line:\n",
    "            current_elseif_count.append(n_spaces)\n",
    "        # Handling rows for IF conditions\n",
    "        if '<' in line or '>' in line:\n",
    "            line, val = line.rsplit(maxsplit=1)\n",
    "            line = line.replace(' '*n_spaces, ' '*n_spaces + front_add)\n",
    "            line = '{} {:g} THEN DO;'.format(line, float(val))\n",
    "        # Handling rows for PREDICTED_VALUE_i\n",
    "        if 'class' in line:\n",
    "            line = line.replace('class:', 'PREDICTED_VALUE_' + str(tree_id + 1) + ' =')\n",
    "            line += ';'\n",
    "            line += '\\n'\n",
    "        line = add_end_front + line\n",
    "        sas_rules += skip + line + '\\n'\n",
    "    sas_rules = sas_rules[:-1]\n",
    "    sas_rules += 'RUN;'\n",
    "    return sas_rules\n",
    "\n",
    "# String to add before row for IF or ELSE IF conditions\n",
    "def get_front_add(count, n_spaces):\n",
    "    \"\"\"\n",
    "        Docstring to be completed\n",
    "    \"\"\"\n",
    "    if count%2 == 0:\n",
    "        toRet = 'END;\\n'+ ' '*(n_spaces+2)+ 'ELSE IF '\n",
    "    else:\n",
    "        toRet = 'IF '\n",
    "    return toRet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trees_rules(input_table, rfclassifier, labels, path, file):\n",
    "    # nouvelle fonction qui exportera toutes les r√®gles dans 1 seul fichier\n",
    "    file = open(path + filename, \"w\")\n",
    "    for index, tree in enumerate(rfclassifier):\n",
    "        rules = get_rules(input_table, tree, index, labels)\n",
    "        file.write(rules + \"\\n\")\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(oob_score=True, random_state=123456)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example \n",
    "iris = datasets.load_iris()\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "# sklearn provides the iris species as integer values since this is required for classification\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[iris.feature_names], iris.target, test_size=0.5, stratify=iris.target, random_state=123456)\n",
    "rf = RandomForestClassifier(n_estimators=100, oob_score=True, random_state=123456)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = export_text(rf[0], feature_names=X_train.columns.to_list(), \n",
    "                        max_depth=100,\n",
    "                        decimals=2,\n",
    "                        spacing=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DATA DECISION_TREE_1;\\nSET DATASET;\\n     IF petal width (cm) <= 1.7 THEN DO;\\n       IF petal length (cm) <= 2.45 THEN DO;\\n         PREDICTED_VALUE_1 = 0.0;\\n\\n       END;\\n       ELSE IF petal length (cm) > 2.45 THEN DO;\\n         PREDICTED_VALUE_1 = 1.0;\\n\\n  END;\\n   END;\\n     ELSE IF petal width (cm) > 1.7 THEN DO;\\n       IF sepal length (cm) <= 6 THEN DO;\\n         IF sepal width (cm) <= 3.1 THEN DO;\\n           PREDICTED_VALUE_1 = 2.0;\\n\\n         END;\\n         ELSE IF sepal width (cm) > 3.1 THEN DO;\\n           PREDICTED_VALUE_1 = 1.0;\\n\\n  END;\\n     END;\\n       ELSE IF sepal length (cm) > 6 THEN DO;\\n         PREDICTED_VALUE_1 = 2.0;\\n\\n  END;\\nEND;\\nRUN;'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rules(tree=rf[0], tree_id=0, features=X_train.columns.to_list(), sas_table=\"DATASET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
